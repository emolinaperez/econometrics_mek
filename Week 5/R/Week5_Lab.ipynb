{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "authorship_tag": "ABX9TyNvo1IdYWK6Nn1qRL8yNF54",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "ir",
      "display_name": "R"
    },
    "language_info": {
      "name": "R"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/emolinaperez/econometrics_mek/blob/main/Week%205/R/Week5_Lab.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Lab 5: Econometrics"
      ],
      "metadata": {
        "id": "_eP9QH_vMHvc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# load packages\n",
        "if (!require(pacman)) install.packages(\"pacman\")\n",
        "p_load('ggplot2', 'sandwich','lmtest', 'estimatr', 'clubSandwich','stargazer') # clubSandwich: for clustered robust standard errors\n"
      ],
      "metadata": {
        "id": "I9sdpntIMEDD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. Load the dataset  \n",
        "\n",
        "Peer Effects, Teacher Incentives, and the Impact of Tracking: Evidence from a Randomized Evaluation in Kenya"
      ],
      "metadata": {
        "id": "-7eIES_hT1NM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "data <- read.csv(\"https://raw.githubusercontent.com/emolinaperez/econometrics_mek/main/Week%205/data/DDK2011_corrected.csv\")"
      ],
      "metadata": {
        "id": "cTClnj7nMY0L"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 2. Data Cleaning and Preparation"
      ],
      "metadata": {
        "id": "ow5ibSsZT5KG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Check for missing values\n",
        "summary(data)"
      ],
      "metadata": {
        "id": "4uCWQrtDT46A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Filter to include only non-missing total scores\n",
        "data_clean <- data[!is.na(data$totalscore), ]"
      ],
      "metadata": {
        "id": "HaRq4-dQT-mR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 3. Exploratory Data Analysis"
      ],
      "metadata": {
        "id": "g3YtNZ23UClv"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Summary statistics\n",
        "str(data_clean)"
      ],
      "metadata": {
        "id": "CZXHMF7OUGe-"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 4. Descriptive Statistics (Replicating Table 1)"
      ],
      "metadata": {
        "id": "z-oBwTc3UW2U"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "descriptive_stats <- function(var) {\n",
        "  mean_tracking <- mean(data_clean[data_clean$tracking == 1, var], na.rm = TRUE)\n",
        "  sd_tracking <- sd(data_clean[data_clean$tracking == 1, var], na.rm = TRUE)\n",
        "  mean_non_tracking <- mean(data_clean[data_clean$tracking == 0, var], na.rm = TRUE)\n",
        "  sd_non_tracking <- sd(data_clean[data_clean$tracking == 0, var], na.rm = TRUE)\n",
        "  p_value <- t.test(data_clean[data_clean$tracking == 1, var],\n",
        "                    data_clean[data_clean$tracking == 0, var])$p.value\n",
        "  return(c(mean_tracking, sd_tracking, mean_non_tracking, sd_non_tracking, p_value))\n",
        "}"
      ],
      "metadata": {
        "id": "LH4hJxtzUZtH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Variables to analyze\n",
        "vars_to_analyze <- c(\"agetest\", \"girl\", \"std_mark\", \"totalscore\")"
      ],
      "metadata": {
        "id": "O_SAFkRyUbpY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Apply the function to the variables\n",
        "descriptive_results <- t(sapply(vars_to_analyze, descriptive_stats))\n",
        "colnames(descriptive_results) <- c(\"Mean_Tracking\", \"SD_Tracking\", \"Mean_Non_Tracking\", \"SD_Non_Tracking\", \"P_Value\")"
      ],
      "metadata": {
        "id": "yDp8_8YaUdSy"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to data frame for easier export\n",
        "descriptive_results_df <- data.frame(Variable = vars_to_analyze, descriptive_results)"
      ],
      "metadata": {
        "id": "dMbKsoSoUfka"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Display the descriptive statistics\n",
        "descriptive_results_df"
      ],
      "metadata": {
        "id": "6Q94MkBNUib8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Visualize the distribution of total scores by tracking status using ggplot\n",
        "p <- ggplot(data_clean, aes(x = totalscore, fill = factor(tracking))) +\n",
        "  geom_histogram(position = \"dodge\", bins = 30, alpha = 0.7) +\n",
        "  facet_wrap(~tracking, labeller = as_labeller(c(`0` = \"Non-Tracking Schools\", `1` = \"Tracking Schools\"))) +\n",
        "  scale_fill_manual(values = c(\"red\", \"blue\")) +\n",
        "  labs(title = \"Distribution of Total Scores by Tracking Status\",\n",
        "       x = \"Total Score\",\n",
        "       y = \"Frequency\",\n",
        "       fill = \"Tracking\") +\n",
        "  theme_minimal()\n",
        "p"
      ],
      "metadata": {
        "id": "3PzIQMS8Vg5U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 5. Replicating Key Results (Replicating Table 2)"
      ],
      "metadata": {
        "id": "zEQaslagVmsJ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Standardize\n",
        "# Z= X−μ/σ\n",
        "data_clean$totalscore_std <- scale(data_clean$totalscore)\n",
        "data_clean$mathscoreraw_std <- scale(data_clean$mathscoreraw)\n",
        "data_clean$litscore_std <- scale(data_clean$litscore)"
      ],
      "metadata": {
        "id": "689-FYdnVmBh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OLS regression for Total Scores\n",
        "model_ols <- lm(totalscore_std ~ tracking, data = data_clean)\n",
        "summary(model_ols)"
      ],
      "metadata": {
        "id": "WjsiwaBAaxiL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#formatted summary table of the OLS regression\n",
        "stargazer(model_ols, type='text')"
      ],
      "metadata": {
        "id": "4emFEBmea3yk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OLS regression for Math Scores\n",
        "model_math <- lm(mathscoreraw_std ~ tracking, data = data_clean)\n",
        "summary(model_math)"
      ],
      "metadata": {
        "id": "y7gmYnC1bwbS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# formatted summary table of the OLS regression\n",
        "stargazer(model_math, type='text', title='Table 2: Math Scores')"
      ],
      "metadata": {
        "id": "Q2f7_nHib35p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OLS regression for Literacy Scores\n",
        "model_literacy <- lm(litscore_std ~ tracking, data = data_clean)\n",
        "summary(model_literacy)"
      ],
      "metadata": {
        "id": "UHi4iwx2cAvU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# formatted summary table of the OLS regression\n",
        "stargazer(model_math, type='text', title='Table 3: Literacy Scores')"
      ],
      "metadata": {
        "id": "uQfGY_ULcEBa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Robust standard errors\n",
        "coeftest(model_ols, vcov = vcovHC(model_ols, type = \"HC1\"))\n",
        "coeftest(model_math, vcov = vcovHC(model_math, type = \"HC1\"))\n",
        "coeftest(model_literacy, vcov = vcovHC(model_literacy, type = \"HC1\"))"
      ],
      "metadata": {
        "id": "-Jk0pfpgcHkg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 6. Clustered Robust Standard Errors"
      ],
      "metadata": {
        "id": "6jdPH_9hcKyz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Assuming clustering at the school level (replace 'school_id' with the actual cluster variable)\n",
        "# Example: Clustered standard errors for total scores\n",
        "model_clustered <- lm(totalscore_std ~ tracking, data = data_clean)\n",
        "summary(model_clustered)\n",
        "\n",
        "cluster_se <- vcovCL(model_clustered, cluster = ~schoolid)\n",
        "coeftest(model_ols, vcov = cluster_se)\n"
      ],
      "metadata": {
        "id": "DA1tsVk3fbAQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 7. Heterogeneous Effects by Achievement Levels"
      ],
      "metadata": {
        "id": "50Oa6d33fmjV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "quartile_cutoffs <- quantile(data_clean$percentile, probs = seq(0, 1, by = 0.25), na.rm = TRUE)\n",
        "data_clean$achievement_quartile <- cut(data_clean$percentile,\n",
        "                                       breaks = quartile_cutoffs,\n",
        "                                       include.lowest = TRUE,\n",
        "                                       labels = 1:4)"
      ],
      "metadata": {
        "id": "9XaLxFjsfmPu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# OLS with interaction terms\n",
        "model_interaction <- lm(totalscore_std ~ tracking * achievement_quartile, data = data_clean)\n",
        "summary(model_interaction)"
      ],
      "metadata": {
        "id": "YbrYBI0lfyGI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 8. Peer Effects Analysis"
      ],
      "metadata": {
        "id": "2HoTwm03f4jG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model_peer_effects <- lm(totalscore_std ~ rMEANstream_std_baselinemark, data = data_clean)\n",
        "summary(model_peer_effects)"
      ],
      "metadata": {
        "id": "Bz8IYhPpf6cM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 9. Regression Discontinuity Analysis (Optional)"
      ],
      "metadata": {
        "id": "lUQm4fzNf9Vz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "rd_data <- data_clean[data_clean$percentile >= 45 & data_clean$percentile <= 55, ]\n",
        "model_rd <- lm(totalscore ~ tracking, data = rd_data)\n",
        "summary(model_rd)"
      ],
      "metadata": {
        "id": "Bz1cRCRHf8w1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 10. Tests for Selection on Observables"
      ],
      "metadata": {
        "id": "h8V3cMO_gC1o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "balance_test <- function(var) {\n",
        "  t.test(data_clean[data_clean$tracking == 1, var],\n",
        "         data_clean[data_clean$tracking == 0, var])\n",
        "}"
      ],
      "metadata": {
        "id": "L5CADkUkgERX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "balance_age <- balance_test(\"agetest\")\n",
        "balance_gender <- balance_test(\"girl\")\n",
        "balance_baseline_score <- balance_test(\"std_mark\")\n",
        "print(balance_age)\n",
        "print(balance_gender)\n",
        "print(balance_baseline_score)"
      ],
      "metadata": {
        "id": "fsJoTsRXgFyK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 11. Consistency Checks"
      ],
      "metadata": {
        "id": "3rACJQLxgKR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "reset_test <- resettest(model_ols, power = 2:3, type = \"fitted\")\n",
        "print(reset_test)"
      ],
      "metadata": {
        "id": "dqi4ZVQKgLml"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bp_test <- bptest(model_ols)\n",
        "print(bp_test)"
      ],
      "metadata": {
        "id": "m8R_5B_fgP2c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 13. Central Limit Theorem (CLT) Build-up Exercise"
      ],
      "metadata": {
        "id": "NtRy9-BogUEP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "set.seed(123)\n",
        "skewed_data <- rexp(10000, rate = 1)\n",
        "\n",
        "sample_means <- function(sample_size, n_samples) {\n",
        "  replicate(n_samples, mean(sample(skewed_data, sample_size, replace = TRUE)))\n",
        "}\n",
        "\n",
        "means_10 <- sample_means(10, 1000)\n",
        "means_30 <- sample_means(30, 1000)\n",
        "means_100 <- sample_means(100, 1000)"
      ],
      "metadata": {
        "id": "0he9dgbYgWDL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clt_data <- data.frame(\n",
        "  sample_mean = c(means_10, means_30, means_100),\n",
        "  sample_size = factor(rep(c(10, 30, 100), each = 1000))\n",
        ")"
      ],
      "metadata": {
        "id": "Trehx3stgYoC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clt_plot <- ggplot(clt_data, aes(x = sample_mean, fill = sample_size)) +\n",
        "  geom_histogram(bins = 20, alpha = 0.7, position = \"identity\") +\n",
        "  facet_wrap(~sample_size, scales = \"free\", ncol = 1) +\n",
        "  labs(title = \"Central Limit Theorem Demonstration\",\n",
        "       x = \"Sample Mean\",\n",
        "       y = \"Frequency\",\n",
        "       fill = \"Sample Size\") +\n",
        "  theme_minimal()"
      ],
      "metadata": {
        "id": "nKW9lwc4gaWS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "clt_plot"
      ],
      "metadata": {
        "id": "5RNtH8CsgcOl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Save the outputs"
      ],
      "metadata": {
        "id": "n5v5nJF2gh21"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stargazer(model_ols,model_math,model_literacy, model_interaction, type='text')\n"
      ],
      "metadata": {
        "id": "8JqR-cEogj_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "stargazer(model_ols,model_math,model_literacy, model_interaction, type = \"html\", title = \"Table 1: results\",\n",
        "          out = \"models.html\")"
      ],
      "metadata": {
        "id": "i209G4oEgjZI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.frame(Age_Balance_Test = balance_age$p.value,\n",
        "                     Gender_Balance_Test = balance_gender$p.value,\n",
        "                     Baseline_Score_Balance_Test = balance_baseline_score$p.value)"
      ],
      "metadata": {
        "id": "DBjeJaO_guyr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data.frame(RESET_Test_pvalue = reset_test$p.value,\n",
        "                     BP_Test_pvalue = bp_test$p.value)"
      ],
      "metadata": {
        "id": "wQSBh_A7gw4U"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}